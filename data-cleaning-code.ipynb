{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0315a235",
   "metadata": {
    "papermill": {
     "duration": 0.010751,
     "end_time": "2023-08-23T11:25:00.427269",
     "exception": false,
     "start_time": "2023-08-23T11:25:00.416518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Data Claning Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74c25a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Filtering missing data\n",
    "data.dropna()#delete all null value both rows and column every null value is deleted\n",
    "data[data.notna()]#this will show except null value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88326c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "dropna =Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much\n",
    "missing data to tolerate.  \n",
    "\n",
    "fillna= Fill in missing data with some value or using an interpolation method such as \"ffill\" or \"bfill\".   \n",
    "\n",
    "isna= Return Boolean values indicating which values are missing/NA.\n",
    "\n",
    "notna =Negation of isna, returns True for non-NA values and False for NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a8785",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code only used for ROWS\n",
    "data.droupna(how='all')#this will delete if all rows value contain NaN Value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f36e79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "* * * example input\n",
    "* 0 1 2\n",
    "* 0 1.0 6.5 3.0\n",
    "* 1 1.0 NaN NaN\n",
    "* 2 NaN NaN NaN\n",
    "* 3 NaN 6.5 3.0\n",
    "* \n",
    "* output\n",
    "* 0 1 2\n",
    "* 0 1.0 6.5 3.0\n",
    "* 1 1.0 NaN NaN\n",
    "* 3 NaN 6.5 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659d7ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# filling and handling missing data filtering and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e65b3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filling and handling missing data filtering and cleaning\n",
    "#this is aplicable only for column \n",
    "data.dropna(axis='columns',how='all')#this will delete all column if column contain null value\n",
    "\n",
    "df.iloc[:4, 1] = np.nan #code use for give null value to column name 1 and till 4 roll all value should be null\n",
    "\n",
    "df.iloc[:2, 2] = np.nan#code means giving null value to column name 2 and till 2nd rows allvalue sholud be null\n",
    "\n",
    "df.dropna(thresh=2)#code means delete starting 2 rows whose walue is nil\n",
    "\n",
    "df.fillna(0)#code means fill null value with zero\n",
    "\n",
    "df.fillna(1:0.5 , 2:0)#code means it will fill NaN Value in 1 column with 0.5, and 2 column with 0 aplicable only for NAN value\n",
    "#reindexing\n",
    "df.iloc[2:1]=np.nan #code means except stating 2 rows in column 1 keep all value NAN and except leaving starting 4 row in column 2 keep all value NaN\n",
    "\n",
    "df.fillna(method='ffill')#code means it will fill all last value in all NAN value\n",
    "#example\n",
    "# column1     column1\n",
    "# 0.2         0.2\n",
    "# 0.234       0.234\n",
    "# 0.1221      0.1221\n",
    "# NaN         0.1221\n",
    "# NaN         0.1221   as u can see all nan value filled with last value in column\n",
    "\n",
    "df.fillna(method='ffill',limit=2)# cade means same as above but it will fill till 2 NaN value as it set a limit for it \n",
    "\n",
    "data.fillna(data.mean())#code means it will fill all NAN value with means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364fd89",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# **Removing Duplicates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf2a27",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**data=pd.DataFrame({'k1':['one','two']*3+['two'],    \n",
    "                     'k2':[1,1,2,3,3,4,4,]})**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6787bc8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame({'k1':['one','two']* 3+['two'],    \n",
    "                   'k2':[1,1,2,3,3,4,4,]})\n",
    "\n",
    "data.duplicate()#code meaans shows true or false for dublicate data dublicate means in whole row contain same value \n",
    "\n",
    "data.drop_duplicate()#code means delete all dublecate rows in all column not in it will not delete if contain in only one row dublicate should in whole selected row\n",
    "\n",
    "data['columname']=range(7)#this will selected only selected column to see dublicate value filter dublicate based on selected column\n",
    "data\n",
    "\n",
    "data.drop_duplicates(subset=['k1'])#code means it will deleted duplicate of selected column\n",
    "\n",
    "data.drop_duplicates(['column1','column2'],keep='last')#code means it will see from bottom it will started deleting dublicate above \n",
    "# exampel      output(after code)\n",
    "# 1    one     1    one           as u can see 2 row is deleted bcz 1 has repeted 2 times  seleted based on 1 column  \n",
    "# 1    two     2    one  \n",
    "# 2    one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474df8f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Transforming data using function or mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737f23a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meat_to_animal={\n",
    "    'bacon':'pig',\n",
    "    'pulled pork'  'pig'\n",
    "    'pastrami':'cow'\n",
    "}\n",
    "data['animal']=data['food'].map(meat_to_animal)#code means it will do mapping according to food column with animal\n",
    "output\n",
    "  food       ounces animal\n",
    "0 bacon       4.0 pig\n",
    "1 pulled pork 3.0 pig\n",
    "2 bacon       12.0 pig\n",
    "3 pastrami    6.0 cow\n",
    "4 corned beef 7.5 cow\n",
    "5 bacon       8.0 pig\n",
    "6 pastrami    3.0 cow\n",
    "7 honey ham   5.0 pig\n",
    "8 nova lox    6.0 salmon  #as u can see animal is maped to food example (where there is a bacon there is a pig) as we have define function\n",
    "\n",
    "#define function\n",
    "def get animal(x):\n",
    "    return meat_to_animal[x]\n",
    "\n",
    "data['food'].map(get_animal)\n",
    "\n",
    "output\n",
    "0 pig\n",
    "1 pig\n",
    "2 pig\n",
    "3 cow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea1187",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Replacing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce033cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.replace(-999,np.nan)#this will delete all -999 value with NAN\n",
    "data.replace([-999,-1000],np.nan)#code mean replace -999 and -1000 with np.nan\n",
    "data.replace([-999,-1000],[np.nan,0])#code mean replace -999 and -1000 with np.nan and 0\n",
    "data.replace({-999:np.nan,-1000:0})#code mean same as above but method is different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5f82b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Renaming Axis Indexes\n",
    "\n",
    "Like values in a Series, axis labels can be similarly transformed by a function or\n",
    "mapping of some form to produce new, differently labeled objects. You can also\n",
    "modify the axes in place without creating a new data structure. Hereâ€™s a simple\n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979963a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)), #code means total value is 12 3rows and 4 column\n",
    "                    index=[\"Ohio\", \"Colorado\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])#code means 1column will be index and with respect to that all column form\n",
    "def transform(x):\n",
    "    return x[:4].upper()\n",
    "data.index.map(transform)\n",
    "index([\"OHIO\", \"COLO\", \"NEW\"])#output of above code\n",
    "\n",
    "data.index=data.index.map(transform)\n",
    "data.rename(index=str.title,columns=str.upper)#column name name will be in upper case\n",
    "data.rename(index={'OHIO','INDIANA'},\n",
    "           columns={'three':'peekaboo'})#it will change column and row name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf22e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Discretization and Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517ef04",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "parenthesis means that the side is open (exclusive)    \n",
    "while the square bracket means it is closed (inclusive).    \n",
    "You can change which side is closed by passing right=False:   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046c11e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "In [77]: ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\n",
    "In [78]: bins = [18, 25, 35, 60, 100]#bins means it will divide the number in this 5 category\n",
    "In [79]: age_categories = pd.cut(ages, bins)\n",
    "In [80]: age_categories#eg 18-25 child,25-35-adult, 35-60-more adult, 60-100-old  \n",
    "#output\n",
    "[[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35,\n",
    "60], (35, 60], (25, 35]]\n",
    "\n",
    "age_categories.categories\n",
    "                \n",
    "age_categories.categories[0]\n",
    "                \n",
    "pd.value_counts(age_categories)#bins count \n",
    "\n",
    "pd.cut(ages,bins,right=False)\n",
    "group_name=[\"Youth\", \"YoungAdult\", \"MiddleAged\", \"Senior\"]\n",
    "pd.cut(ages,bins,labels=group_names)\n",
    "#output\n",
    "['Youth', 'Youth', 'Youth', 'YoungAdult', 'Youth', ..., 'YoungAdult', 'Senior', '\n",
    "MiddleAged', 'MiddleAged', 'YoungAdult']\n",
    " \n",
    "data=np.random.uniform(size=20) #The precision=2 option limits the decimal precision to two digits\n",
    "pd.cut(data,4,precision=2) #data means dataframe, 4 means 4 category,precision 2 menas till 2 decimal \n",
    "#output\n",
    " [(0.34, 0.55], (0.34, 0.55], (0.76, 0.97], (0.76, 0.97], (0.34, 0.55], ..., (0.34\n",
    ", 0.55], (0.34, 0.55], (0.55, 0.76], (0.34, 0.55], (0.12, 0.34]] #this is equal size bins\n",
    "\n",
    "In [90]: data = np.random.standard_normal(1000)\n",
    "In [91]: quartiles = pd.qcut(data, 4, precision=2)#there is 2 cut and qcut \n",
    "In [92]: quartiles\n",
    "\n",
    "pd.value_counts(quartiles)\n",
    "                                                    \n",
    "pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.]).value_counts()\n",
    "                                                    \n",
    "                                                    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d8590",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Deleting and Filtering Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a56854",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The parentheses around data.abs() > 3 are necessary in order to call the any method on the result of the comparison operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062739d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "col=data[2]\n",
    "col[col.abs()>3]#code to find value in one columns exceeding 3 in absolute value\n",
    "data[data.abs()>3.any(axis='column')]#code means show (value>3) in all column of dataset (any) is used for all dataframe\n",
    "#output\n",
    "41 0.457246 -0.025907 -3.399312 -0.974657\n",
    "60 1.951312 3.260383 0.963301 1.201206\n",
    "136 0.508391 -0.196713 -3.745356 -1.520113#as u can see there is in each row ther is -3.00 so it show this output\n",
    "\n",
    "data[data.abs() > 3] = np.sign(data) * 3 #this will convert all -3 value into 3 means (+3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9627eba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Permutation and Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5b10f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(5 * 7).reshape((5, 7)))#5 multipy 7 means number total is 35 and rows 5 and 7 column\n",
    "sampler=np.random.permutation(5)\n",
    "sampler\n",
    "#output\n",
    "Out[106]: array([3, 1, 4, 2, 0])#purmutation meansall possible can genrate to get 5 \n",
    "\n",
    "In [109]: column_sampler = np.random.permutation(7)\n",
    "In [110]: column_sampler\n",
    "Out[110]: array([4, 6, 3, 2, 1, 0, 5])\n",
    "In [111]: df.take(column_sampler, axis=\"columns\")#this code usefull for column all column name change to based on output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1506795",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Computing Indicator/Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5cf59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"],\n",
    "                   \"data1\": range(6)})\n",
    "pd.get_dummies(df['key'])#this will create dummy variable using key\n",
    "\n",
    "dummies=pd.get_dummies(df['key'],prefix='key')\n",
    "\n",
    "df_with_dummy = df[[\"data1\"]].join(dummies)\n",
    "\n",
    "dummies=movies['genres'].str.get_dummies('|') #this will return dummary value according to genres ccolumn unique value\n",
    "dummies.iloc[:10,:6]#means show till 10 rows and 6 column as total unique in column of genres\n",
    "\n",
    "movies_windic = movies.join(dummies.add_prefix(\"Genre_\")) #mean add genre at first of every geners\n",
    "movies_windic.iloc[0]#this means taking first rows\n",
    "#output:\n",
    "# title Toy Story (1995)\n",
    "# genres Animation|Children's|Comedy\n",
    "# Genre_Action 0\n",
    "# Genre_Adventure 0\n",
    "# Genre_Animation 1\n",
    "# Genre_Children's 1  #as u can see it a animation and children movie\n",
    "\n",
    "np.random.seed(12345) # to make the example repeatable\n",
    "values = np.random.uniform(size=10) #creating some random number size 10\n",
    "value #here 10 randome number genrated\n",
    "\n",
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1] #now we are binning that 10 number in this format\n",
    "pd.get_dummies(pd.cut(values, bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4cc30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Extension Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791f4f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, None])#we create series not dataframe\n",
    "\n",
    "s.dtype#to check the datatype of column\n",
    "\n",
    "s = pd.Series([1, 2, 3, None], dtype=pd.Int64Dtype())#we mension dtype in series as int \n",
    "#we can also use \"\"int64\"\" insted of \"\"Int65Dtype\"\"\n",
    "\n",
    "s[3] is pd.NA #tocheck null value it will return true or false\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2, None, 4],\n",
    "                   \"B\": [\"one\", \"two\", \"three\", None],\n",
    "                   \"C\": [False, None, False, True]}) #this we create dataframe not series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff754f4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a41504",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val = \"a,b, guido\"\n",
    "val.split(\",\") #we can break string into pieces with split method\n",
    "# Out[152]: ['a', 'b', ' guido']\n",
    "\n",
    "\"::\".join(pieces)\n",
    "# Out[157]: 'a::b::guido'\n",
    "\n",
    "\"guido\" in val\n",
    "# Out[158]: True\n",
    "\n",
    "val.replace(\",\", \"::\") #we can replace\n",
    "# Out[163]: 'a::b:: guido'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd1f9f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#  Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd243ec9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "IMPORTANT FOR DATA CLEANING PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bedef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#to replace or find or search word in whole sentences we use regular exptession\n",
    "import re\n",
    "text = \"foo bar\\t baz \\tqux\" #This is messy text now we will clean this \n",
    "\n",
    "re.split(r\"\\s+\", text) #we arrange in properf format in split method\n",
    "# Out; ['foo', 'bar', 'baz', 'qux']\n",
    "\n",
    "regex = re.compile(r\"\\s+\") #we can also write this code as above ones \n",
    "regex.split(text) #regx split are another method \n",
    "# out:['foo', 'bar', 'baz', 'qux'] \n",
    "\n",
    "\n",
    "regex.findall(text)\n",
    "# Out[170]: [' ', '\\t ', ' \\t']\n",
    "\n",
    "text = \"\"\"Dave dave@google.com\n",
    "Steve steve@gmail.com\n",
    "Rob rob@gmail.com\n",
    "Ryan ryan@yahoo.com\"\"\"\n",
    "pattern = r\"[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\"\n",
    "# re.IGNORECASE makes the regex case insensitive\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "regex.findall(text) #as u can see all email data is clean now\n",
    "# out:\n",
    "# ['steve@gmail.com',\n",
    "# 'rob@gmail.com',\n",
    "# 'ryan@yahoo.com']\n",
    "\n",
    "print(regex.match(text))\n",
    "\n",
    "m = regex.search(text)#this only search only first word \n",
    "\n",
    "pattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "    \n",
    "regex.findall(text)\n",
    "\n",
    "In [183]: print(regex.sub(r\"Username: \\1, Domain: \\2, Suffix: \\3\", text))\n",
    "#output\n",
    "# Dave Username: dave, Domain: google, Suffix: com\n",
    "# Steve Username: steve, Domain: gmail, Suffix: com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d243c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<!-- findall   Return all nonoverlapping matching patterns in a string as a           list   \n",
    "\n",
    "finditer   Like findall, but returns an iterator   \n",
    "\n",
    "match      Match pattern at start of string and optionally segment                pattern components into groups; if the pattern\n",
    "           matches, return a match object, and otherwise None  \n",
    "           \n",
    "search     Scan string for match to pattern, returning a match object            if so; unlike match, the match can be anywhere in\n",
    "           the string as opposed to only at the beginning   \n",
    "           \n",
    "split      Break string into pieces at each occurrence of pattern  \n",
    "\n",
    "sub, subn  Replace all (sub) or first n occurrences (subn) of pattern            in string with replacement expression; use symbols\n",
    "            \\1, \\2, ... to refer to match group elements in the                  replacement string  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc2bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T08:55:40.183113Z",
     "iopub.status.busy": "2023-08-23T08:55:40.182547Z",
     "iopub.status.idle": "2023-08-23T08:55:40.214915Z",
     "shell.execute_reply": "2023-08-23T08:55:40.213560Z",
     "shell.execute_reply.started": "2023-08-23T08:55:40.183077Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.findall \n",
    "# Return all nonoverlapping matching patterns in a string as a list\n",
    "# 2.finditer\n",
    "# Like findall, but returns an iterator\n",
    "# 3.match \n",
    "# Match pattern at start of string and optionally segment pattern components into groups; if the pattern\n",
    "# matches, return a match object, and otherwise None\n",
    "# 4.search\n",
    "# Scan string for match to pattern, returning a match object if so; unlike match, the match can be anywhere in\n",
    "# the string as opposed to only at the beginning\n",
    "# 5.split \n",
    "# Break string into pieces at each occurrence of pattern\n",
    "# 6.sub, subn \n",
    "# Replace all (sub) or first n occurrences (subn) of pattern in string with replacement expression; use symbols\n",
    "# \\1, \\2, ... to refer to match group elements in the replacement string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5866c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# String Function in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ce749",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.str.contains(\"gmail\")\n",
    "\n",
    "# cat       =Concatenate strings element-wise with optional delimiter\n",
    "# contains  = Return Boolean array if each string contains pattern/regex\n",
    "# count     = Count occurrences of pattern\n",
    "# extract   = Use a regular expression with groups to extract one or more strings from a Series of strings; the result\n",
    "# will be a DataFrame with one column per group\n",
    "\n",
    "# endswith  = Equivalent to x.endswith(pattern) for each element\n",
    "# startswith= Equivalent to x.startswith(pattern) for each element\n",
    "# findall   = Compute list of all occurrences of pattern/regex for each string\n",
    "# get Index into each element (retrieve i-th element)\n",
    "\n",
    "# isalnum   = Equivalent to built-in str.alnum\n",
    "# isalpha   =Equivalent to built-in str.isalpha\n",
    "# isdecimal = Equivalent to built-in str.isdecimal\n",
    "# isdigit   =Equivalent to built-in str.isdigit\n",
    "# islower   =Equivalent to built-in str.islower\n",
    "# isnumeric = Equivalent to built-in str.isnumeric\n",
    "# isupper   =Equivalent to built-in str.isupper\n",
    "# join      =Join strings in each element of the Series with passed separator\n",
    "# len       =Compute length of each string\n",
    "# lower,upper= Convert cases; equivalent to x.lower() or x.upper() for each element\n",
    "# match     =Use re.match with the passed regular expression on each element, returning True or False\n",
    "# whether it matches\n",
    "# pad       =Add whitespace to left, right, or both sides of strings\n",
    "# center    = Equivalent to pad(side=\"both\")\n",
    "# repeat    =Duplicate values (e.g., s.str.repeat(3) is equivalent to x * 3 for each string)\n",
    "# replace   =Replace occurrences of pattern/regex with some other string\n",
    "# slice Slice each string in the Series\n",
    "# split     = Split strings on delimiter or regular expression\n",
    "# strip     =Trim whitespace from both sides, including newlines\n",
    "# rstrip    =Trim whitespace on right side\n",
    "# lstrip    =Trim whitespace on left side\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21566974",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fededc8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Background and Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa64a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.unique(values)#to see unique value\n",
    "\n",
    "pd.value_counts(values)\n",
    "\n",
    "dim.take (value)\n",
    "\n",
    "N=len(fruits)\n",
    "\n",
    "my_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar'])\n",
    "my_categories\n",
    "# Out[223]:\n",
    "# ['foo', 'bar', 'baz', 'foo', 'bar']\n",
    "# Categories (3, object): ['bar', 'baz', 'foo']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9e4ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Computations with Categoricals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11341444",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = pd.qcut(draws, 4)\n",
    "bins#create 4 range of in dtaframe using bins all data convert into form \n",
    "\n",
    "bins = pd.qcut(draws, 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "bins\n",
    "\n",
    "# Out\n",
    "# ['Q1', 'Q4', 'Q1', 'Q2', 'Q2', ..., 'Q3', 'Q3', 'Q2', 'Q3', 'Q2']\n",
    "# Length: 1000\n",
    "# Categories (4, object): ['Q1' < 'Q2' < 'Q3' < 'Q4']\n",
    "\n",
    ": bins = pd.Series(bins, name='quartile')\n",
    ": results = (pd.Series(draws)\n",
    " .....:      groupby(bins)\n",
    " .....: .    agg(['count', 'min', 'max'])\n",
    " .....: .    reset_index())\n",
    "  \n",
    " # out\n",
    "# quartile count min max\n",
    "# 0 Q1 250 -3.119609 -0.678494\n",
    "# 1 Q2 250 -0.673305 0.008009\n",
    "# 2 Q3 250 0.018753 0.686183\n",
    "\n",
    "In [248]: %time _ = labels.astype('category') #to see the cpu usage\n",
    "# CPU times: user 469 ms, sys: 106 ms, total: 574 ms\n",
    "# Wall time: 577 ms  \n",
    "\n",
    "s = pd.Series(['a', 'b', 'c', 'd'] * 2)\n",
    "cat_s = s.astype('category') #category can be use as dfype as object\n",
    "cat_s#we are forming category\n",
    "\n",
    "cat_s.cat.codes #using data as code in int format\n",
    "\n",
    "cat_s.cat.categories#see the category of data\n",
    "\n",
    "cat_s3 = cat_s[cat_s.isin(['a', 'b'])]#this will show only a and b value\n",
    "\n",
    "pd.get_dummies(cat_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.972071,
   "end_time": "2023-08-23T11:25:01.755147",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-23T11:24:49.783076",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
